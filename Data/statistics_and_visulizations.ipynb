{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f67da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")\n",
    "import itertools\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ddef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- USER CONFIGURATION ----------------------\n",
    "# 1. Path to your saved model weights (e.g., best_model_efficientnet_b0.pth)\n",
    "MODEL_PATH = r\"\\best_model_efficientnet_b0.pth\"\n",
    "\n",
    "# 2. Test data directory structured for torchvision.datasets.ImageFolder:\n",
    "#    TEST_DIR/\n",
    "#       class0_name/\n",
    "#         img1.png\n",
    "#         img2.png\n",
    "#         ...\n",
    "#       class1_name/\n",
    "#         ...\n",
    "#    (Ensure the subfolder names exactly match your class labels, e.g., \"wP\", \"wR\", ..., \"empty\")\n",
    "TEST_DIR   = r\"\"\n",
    "\n",
    "# 3. Batch size for DataLoader\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 4. Device (GPU if available, otherwise CPU)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ------------------------------------------\n",
    "    # (A) Load Test Dataset with ImageFolder\n",
    "    # ------------------------------------------\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    test_dataset = datasets.ImageFolder(root=TEST_DIR, transform=test_transforms)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    idx_to_class = test_dataset.classes\n",
    "    num_classes   = len(idx_to_class)\n",
    "    print(f\"[INFO] Found {num_classes} classes: {idx_to_class}\")\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # (B) Rebuild EfficientNet-B0 and Load Weights\n",
    "    # ---------------------------------------------\n",
    "    print(\"[INFO] Creating EfficientNet-B0 model\")\n",
    "    model = timm.create_model('efficientnet_b0', pretrained=False, num_classes=num_classes)\n",
    "    print(f\"[INFO] Loading weights from: {MODEL_PATH}\")\n",
    "    state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    # ----------------------------------------------\n",
    "    # (C) Inference: Collect True Labels & Predictions\n",
    "    # ----------------------------------------------\n",
    "    print(\"[INFO] Running inference on test set...\")\n",
    "    all_labels = []\n",
    "    all_preds  = []\n",
    "    all_probs  = []\n",
    "\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            probs   = softmax(outputs)\n",
    "            _, preds = torch.max(probs, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds  = np.array(all_preds)\n",
    "    all_probs  = np.array(all_probs)\n",
    "    print(\"[INFO] Inference complete.\")\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # (D) Confusion Matrix Heatmap (Normalized)\n",
    "    # ------------------------------------------------\n",
    "    print(\"[INFO] Generating confusion matrix...\")\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(num_classes)))\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Normalized Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, idx_to_class, rotation=90)\n",
    "    plt.yticks(tick_marks, idx_to_class)\n",
    "\n",
    "    thresh = cm_norm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm_norm.shape[0]), range(cm_norm.shape[1])):\n",
    "        val = cm_norm[i, j]\n",
    "        plt.text(j, i, f\"{val:.2f}\",\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if val > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confusion_matrix.png\", dpi=300)\n",
    "    plt.close()\n",
    "    print(\"[INFO] Saved: confusion_matrix.png\")\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # (E) Precision, Recall, F1-score Bar Charts per Class\n",
    "    # ---------------------------------------------------\n",
    "    print(\"[INFO] Computing precision, recall, F1-score per class...\")\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, labels=list(range(num_classes)), zero_division=0\n",
    "    )\n",
    "\n",
    "    x = np.arange(num_classes)\n",
    "    width = 0.25\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(x - width, precision, width, label='Precision')\n",
    "    plt.bar(x,         recall,    width, label='Recall')\n",
    "    plt.bar(x + width, f1,        width, label='F1-Score')\n",
    "    plt.xticks(x, idx_to_class, rotation=90)\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Precision, Recall, F1-Score per Class')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"prf_bar_chart.png\", dpi=300)\n",
    "    plt.close()\n",
    "    print(\"[INFO] Saved: prf_bar_chart.png\")\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # (F) ROC Curves per Class (using probability outputs)\n",
    "    # ---------------------------------------------------\n",
    "    print(\"[INFO] Generating ROC curves per class...\")\n",
    "    # Binarize true labels for multi-class ROC\n",
    "    all_labels_bin = np.zeros((all_labels.size, num_classes))\n",
    "    for i, lbl in enumerate(all_labels):\n",
    "        all_labels_bin[i, lbl] = 1\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(num_classes):\n",
    "        fpr, tpr, _ = roc_curve(all_labels_bin[:, i], all_probs[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"{idx_to_class[i]} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Each Class')\n",
    "    plt.legend(loc='lower right', fontsize='small')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"roc_curves.png\", dpi=300)\n",
    "    plt.close()\n",
    "    print(\"[INFO] Saved: roc_curves.png\")\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # (G) Model Architecture Summary (Text)\n",
    "    # ---------------------------------------\n",
    "    print(\"\\n=== Model Architecture ===\")\n",
    "    print(model)\n",
    "    print(\"\\n=== Detailed Layer-by-Layer Summary ===\")\n",
    "    summary(model, (3, 224, 224))  # Adjust input size if different\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
